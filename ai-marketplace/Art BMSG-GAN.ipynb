{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Art BMSG-GAN",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "DRgMcE_sj_dS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MgqzKUjayp9",
        "colab_type": "text"
      },
      "source": [
        "# Art BMSG-GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKkuFZIRpJrH",
        "colab_type": "text"
      },
      "source": [
        "Notebook authored by Jeremy Webb\n",
        "\n",
        "BMSG-GAN package by [Animesh Karnewar](https://akanimax.github.io/) can be found in this repository: https://github.com/akanimax/BMSG-GAN.\n",
        "\n",
        "This notebook gathers a dataset of images of art in a specific genre and trains a GAN to produce similar art.\n",
        "\n",
        "Below are some examples of landscapes generated by a GAN trained with this notebook.\n",
        "\n",
        "<div align=center>\n",
        "  <img src=\"https://gitlab.com/iota-lab/ai-marketplace/raw/master/GAN_landscapes.png\" alt=\"Generated Landscape Examples\" width=\"50%\"/>\n",
        "</div>\n",
        "\n",
        "---\n",
        "\n",
        "**To train a GAN, read and run each cell below in order by clicking on the play button on the left side.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRgMcE_sj_dS",
        "colab_type": "text"
      },
      "source": [
        "## License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyY1QItNjrRA",
        "colab_type": "text"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Jeremy Webb\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40OsWqIEqMc9",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw0qkhs8pOUN",
        "colab_type": "text"
      },
      "source": [
        "Check that you are using a GPU for training by choosing *Runtime->Change runtime type->Hardware accelerator = GPU*.\n",
        "\n",
        "If something goes wrong while running these instructions, you can start with a clean slate by doing *Runtime->Reset all runtimes...* This will delete everything and give you a fresh server instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHhHbLiJbulm",
        "colab_type": "text"
      },
      "source": [
        "Define some utility functions and imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNbJhTLaoll3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display\n",
        "from ipywidgets import IntProgress\n",
        "import os\n",
        "import re\n",
        "\n",
        "class ProgressBar():\n",
        "  def __init__(self, maxValue = 100, startValue = 0):\n",
        "    self.pBar = IntProgress(min=0, max = maxValue)\n",
        "    self.maxValue = maxValue\n",
        "    self.updateInterval = 1\n",
        "    if self.maxValue > 150:\n",
        "      self.updateInterval = int(self.maxValue / 100)\n",
        "    display(self.pBar) # display the bar\n",
        "\n",
        "  def update(self, value):\n",
        "    if value % self.updateInterval == 0:\n",
        "      self.pBar.value = value\n",
        "    if(value == self.maxValue):\n",
        "      self.pBar.bar_style = 'success'\n",
        "\n",
        "\n",
        "def count_items(directory):\n",
        "  dirs = os.listdir(directory)\n",
        "  return len(dirs)\n",
        "\n",
        "def getEpochReached(search_dir):\n",
        "  model_files = os.listdir(search_dir)\n",
        "  max_epoch = 0\n",
        "  for f in model_files:\n",
        "    if os.path.isfile(search_dir + f):\n",
        "      # number for epoch should be in last part of filename\n",
        "      # filename example: \"GAN_GEN_1.pth\"\n",
        "      num = re.search(r'\\d+', f)\n",
        "      if num:\n",
        "        num = int(num.group())\n",
        "        if num > max_epoch:\n",
        "          max_epoch = num\n",
        "  return max_epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlyhNZ2TS3PW",
        "colab_type": "text"
      },
      "source": [
        "### Clone the BMSG-GAN Repository\n",
        "Git clone the GAN repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8FljGROSvMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/akanimax/BMSG-GAN\n",
        "# the below is necessary because the current master branch of the repository\n",
        "# uses defaults set for AWS SageMaker\n",
        "# these defaults cause errors when they are parsed during setup and don't exist\n",
        "# so checkout a version without these defaults\n",
        "!cd BMSG-GAN/ && git checkout 1d3a719910504714438f71e92714567e491f488e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgahzclrbzIF",
        "colab_type": "text"
      },
      "source": [
        "### Mounting Google Drive\n",
        "\n",
        "Using Google Drive to save the trained models automatically is recommended, but not required. In order to use Google Drive, you will need to have at least 4 GB of free space for storing model files, and optionally, samples generated during training.\n",
        "\n",
        "The advantages of using Google Drive are that the model files will be automatically stored in case your notebook gets disconnected during training so you will not lose much progress. Additionally, if you save the samples generated during training to your Google Drive, you can see how the GAN is progressing.\n",
        "\n",
        "If you do not use Google Drive, resuming training will be much more difficult because you will need to ensure that you download the latest model files before your notebook server is restarted (the server will automatically restart after 12 hours) and then upload them again when you want to resume. The largest size image that can be trained with decent results in one day is 64x64 pixels.\n",
        "\n",
        "If you decide not to use Google Drive, set `use_drive = False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZ1QhaCA_aH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title { form-width: \"40%\" }\n",
        "\n",
        "#@markdown If checked, training data will be stored in Google Drive.\n",
        "use_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "if use_drive:\n",
        "  drive.mount('/content/drive')\n",
        "  if not os.path.exists(\"/content/drive/My Drive/Colab Notebooks/\"):\n",
        "    print(\"Note: Create 'Colab Notebooks' directory in drive root to proceed.\")\n",
        "else:\n",
        "  print(\n",
        "        \"Warning: Your models will not be saved automatically. \"\n",
        "        \"Make sure to download the models periodically to avoid \"\n",
        "        \"loss of progress.\"\n",
        "       )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_df2X69f8KO",
        "colab_type": "text"
      },
      "source": [
        "### Choose Genre\n",
        "\n",
        "If you don't have your own dataset, it is recommended to choose a genre from [this list on Wikiart](https://www.wikiart.org/en/paintings-by-genre). A dataset of artwork in the public domain will be scraped from Wikiart. It is a good idea to choose a genre with more pieces of art so the GAN has enough training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYb9WN4DlFmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "genre = 'landscape' #@param {type: \"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7204ygnSq6q7",
        "colab_type": "text"
      },
      "source": [
        "### Define Default Directories\n",
        "\n",
        "Define the default directories for saving the training data and results.\n",
        "\n",
        "If you are using Google Drive and want to store the samples generated during training in Google Drive, set `samples_in_drive` to `True`. This will require additional storage space in Google Drive, but will enable you to see how the GAN is progressing as it trains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYE733CB0toH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Store Samples in Google Drive? { run: \"auto\", form-width: \"40%\" }\n",
        "\n",
        "#@markdown If checked, samples generated from training will be stored in Drive\n",
        "samples_in_drive = True #@param {type: \"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "if use_drive:\n",
        "  main_dir = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "else:\n",
        "  main_dir = \"/content/BMSG-GAN/\"\n",
        "\n",
        "data_dir = main_dir + \"Data/\"\n",
        "bmsggan_dir = data_dir + \"BMSG-GAN/\"\n",
        "\n",
        "base_dir = \"/content/BMSG-GAN/data/\"\n",
        "if not os.path.exists(base_dir):\n",
        "    print(\"Clone git repository above first!\")\n",
        "else:\n",
        "  # original images directory\n",
        "  train_dir = base_dir + genre + \"/original/\"\n",
        "  if not os.path.exists(train_dir):\n",
        "      os.makedirs(train_dir)\n",
        "\n",
        "  # processed images directory\n",
        "  processed_dir = base_dir + genre + \"/processed/\"\n",
        "  if not os.path.exists(processed_dir):\n",
        "      os.makedirs(processed_dir)\n",
        "  \n",
        "  # saved models directory\n",
        "  models_dir = bmsggan_dir + genre + \"/Models/\"\n",
        "  if not os.path.exists(models_dir):\n",
        "      os.makedirs(models_dir)\n",
        "      \n",
        "  # samples directory\n",
        "  if samples_in_drive and use_drive:\n",
        "    samples_dir = bmsggan_dir + genre + \"/samples/\"\n",
        "  else:\n",
        "    samples_dir = base_dir + genre + \"/samples/\"\n",
        "  if not os.path.exists(samples_dir):\n",
        "      os.makedirs(samples_dir)\n",
        "      \n",
        "  # logs directory\n",
        "  logs_dir = base_dir + genre + \"/logs/\"\n",
        "  if not os.path.exists(logs_dir):\n",
        "      os.makedirs(logs_dir)\n",
        "      \n",
        "  print(\"Directories created successfully\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRvNccj7CIu",
        "colab_type": "text"
      },
      "source": [
        "### Set Target Image Size\n",
        "\n",
        "Images produced by the GAN are square. The `target_size` parameter defines how large the images should be. It needs to be a power of 2 (i.e. 4, 8, 16, 32, 64, 128, 256, 512). 512 is the largest this parameter can be and still run the BMSG-GAN on Google Colab (at the time of writing).\n",
        "\n",
        "Choose the `target_size` parameter carefully. Although bigger pictures are attractive, they also take a lot longer to train. For example, with a `target_size` of 512, training on a decently-sized dataset (1000s of images) can take a few weeks on Google Colab. Using a `target_size` of 128, recognizable images could be obtained within a couple days. If you are not using Google Drive to store intermediate results, it is recommended that `target_size` be no larger than 64 to allow training to finish in one day (less than the max running time of Google Colab - 12 hours)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjC7VxEN7Cl5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title  { run: \"auto\", vertical-output: true }\n",
        "\n",
        "import math\n",
        "\n",
        "# size in pixels of the generated images\n",
        "target_size = \"512\" #@param [4, 8, 16, 32, 64, 128, 256, 512]\n",
        "target_size = int(target_size)\n",
        "\n",
        "if math.log2(target_size) % 1 != 0:\n",
        "  raise ValueError('target_size must be a power of 2')\n",
        "\n",
        "print(f'target_size set to {target_size}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB8oS70DrPIO",
        "colab_type": "text"
      },
      "source": [
        "## Setup the Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WujnP907kdM",
        "colab_type": "text"
      },
      "source": [
        "### Unzip the data if it exists\n",
        "\n",
        "If the data exists in a zip directory inside the `data_dir`, extract it. If you have your own dataset, upload it to `data_dir` before running this cell. Otherwise try and scrape Wikiart for the dataset in the next section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyJhe_o113gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "found_training_data = False\n",
        "files = os.listdir(data_dir)\n",
        "for f in files:\n",
        "  filename = os.path.join(data_dir, f)\n",
        "  if os.path.isfile(filename) and f.startswith(genre) and f.endswith('.zip'):\n",
        "    found_training_data = True\n",
        "    !unzip -o \"{filename}\" -d \"{train_dir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-whdP-ac7AS3",
        "colab_type": "text"
      },
      "source": [
        "### Scrape Wikiart for Artwork in Genre\n",
        "\n",
        "This cell will scrape Wikiart for art pieces in the specified genre. Run it if you do not have your own dataset. If `use_drive` is `True`, a zipfile of the images will also be saved to drive so that the images don't have to be downloaded in the future, and instead can be simply extracted (see above cell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GieZQfKEphor",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not found_training_data:\n",
        "  # scrape Wikiart for the dataset since it wasn't found in previous step\n",
        "  import os\n",
        "  import urllib.request\n",
        "  import json\n",
        "  import requests\n",
        "  import re\n",
        "  import itertools\n",
        "  import multiprocessing\n",
        "  from multiprocessing.dummy import Pool\n",
        "  import zipfile\n",
        "\n",
        "  # total pages to scrape, \n",
        "  # can be larger than available pages (if you don't know how many there are)\n",
        "  pages = 100\n",
        "\n",
        "  # genre_to_scrape can be any one of the values found on the\n",
        "  # following page: https://www.wikiart.org/en/paintings-by-genre\n",
        "  # choose one that has enough paintings to train with,\n",
        "  # a good amount is in the 1000s\n",
        "\n",
        "  class PaintingInfo:\n",
        "    def __init__(self, url, title):\n",
        "      self.url = url\n",
        "      self.title = title\n",
        "\n",
        "    def getValidFilename(self):\n",
        "      maxNameLen = 180\n",
        "      s = self.title.strip().replace(' ', '_').lower()\n",
        "      if len(s) > maxNameLen:\n",
        "          s = s[:maxNameLen]\n",
        "      s = re.sub('[^A-Za-z0-9\\.\\-_]+', '.', s)\n",
        "      return s\n",
        "\n",
        "  # get list of all links to paintings of the specified genre\n",
        "  def get_painting_list(count, genre):\n",
        "    url = \"https://www.wikiart.org/en/paintings-by-genre/\" \\\n",
        "        + genre+ \"/\" + str(count) + \"?json=1\"\n",
        "    response = requests.get(url, allow_redirects=False)\n",
        "    response.raise_for_status()\n",
        "    if(response.status_code >= 300 or len(response.json()) == 0):\n",
        "        # when the page count is invalid, a 300 redirect is returned\n",
        "        # we don't want to do anymore processing after this\n",
        "        return None, False\n",
        "    data = response.json()\n",
        "    url_list = []\n",
        "    print(\"Processing {} elements\".format(len(data)))\n",
        "    for item in data:\n",
        "        name = item['image']\n",
        "        exclamationLoc = name.find('!')\n",
        "        if exclamationLoc >= 0:\n",
        "            name = name[:exclamationLoc]\n",
        "        url_list.append(PaintingInfo(name, item['title']))\n",
        "    return url_list, True\n",
        "\n",
        "  def downloader(paintingInfo, genre, save_directory):\n",
        "    item, painting = paintingInfo\t\n",
        "    name = save_directory + painting.getValidFilename() + \".jpg\"\n",
        "\n",
        "    if item != 0 and item % 100 == 0:\n",
        "        print(\"Downloaded {} images\".format(item))\n",
        "\n",
        "    # skip if the file is already downloaded\n",
        "    if not os.path.exists(name):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(painting.url, name)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            try:\n",
        "                s = \"Failed to download: \" + painting.url\n",
        "                print(s)\n",
        "            except UnicodeEncodeError:\n",
        "                # avoid crashing because characters are unicode encoded\n",
        "                print(\"Failed to download file\")\t\n",
        "\n",
        "\n",
        "  def run_scraper(genre, save_directory):\n",
        "    if not os.path.exists(save_directory):\n",
        "        os.makedirs(save_directory)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"Compiling list of paintings to download...\")\n",
        "    for i in range(1, pages + 1):\n",
        "        result, isValid = get_painting_list(i, genre)\n",
        "        if isValid:\n",
        "            results.extend(result)\n",
        "        else:\n",
        "            break\n",
        "    print(\"Starting to download {} images...\".format(len(results)))\n",
        "    pool_of_threads = Pool(max(1, multiprocessing.cpu_count() - 1))\n",
        "    pool_of_threads.starmap(\n",
        "        downloader,\n",
        "        zip(enumerate(results),\n",
        "            itertools.repeat(genre),\n",
        "            itertools.repeat(save_directory)\n",
        "           )\n",
        "    )\n",
        "    pool_of_threads.close()\n",
        "\n",
        "  print(\"Starting scraping...\")\n",
        "  run_scraper(genre, train_dir)\n",
        "  \n",
        "  # if using drive,\n",
        "  # create a zip file of the images and store them for future use\n",
        "  if use_drive:\n",
        "    print(\"Saving data\")\n",
        "    zipfile_name = data_dir + genre + \".zip\"\n",
        "    files_to_store = os.listdir(train_dir)\n",
        "    with zipfile.ZipFile(zipfile_name, \"w\", zipfile.ZIP_DEFLATED) as zipdir:\n",
        "      for f in files_to_store:\n",
        "        zipdir.write(train_dir + f, f)\n",
        "\n",
        "  print(\"All done!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2olGwNIsowY9",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess the Training Images\n",
        "Remove alpha channel from images, which messes up training, and resize the images to the target size. The images are resized to width = target_size and height = target_size regardless of their aspect ratio, meaning that some of them can become distorted. However, this gives pretty good results anyway. If you are so inclined, you could put together an algorithm that does intelligent cropping, centering, and resizing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy3CfHklotKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os, sys\n",
        "\n",
        "path = train_dir\n",
        "out_path = processed_dir\n",
        "\n",
        "dirs = os.listdir(path)\n",
        "print(f\"Found {len(dirs)} images.\")\n",
        "progress = ProgressBar(maxValue = len(dirs) - 1)\n",
        "\n",
        "for i, item in enumerate(dirs):\n",
        "    if os.path.isfile(path+item):\n",
        "        im = Image.open(path+item)\n",
        "        RGB = im.convert('RGB')\n",
        "        processed_im = RGB.resize((target_size, target_size))\n",
        "        processed_im.save(out_path + item, 'JPEG', quality=90)\n",
        "    progress.update(i)\n",
        "    \n",
        "print(\"Processed all images.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d8I4Q4_Lxw2",
        "colab_type": "text"
      },
      "source": [
        "Delete any images that can't be opened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABFKzHUONefC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@markdown Verify that training images are all valid\n",
        "verify = True #@param {type: \"boolean\"}\n",
        "if verify:\n",
        "  from fastai.vision import verify_images\n",
        "  verify_images(processed_dir, delete=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jJdehU8L4Mt",
        "colab_type": "text"
      },
      "source": [
        "### Check Training Images\n",
        "\n",
        "Show some images and check that they look good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KauTzdRTNhwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show some of the images\n",
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "\n",
        "# image directory, grid size for plot\n",
        "def plot_images(img_directory, n):\n",
        "  imgs = os.listdir(img_directory)\n",
        "  if len(imgs) < n * n:\n",
        "    print(\"Not enough images to display\")\n",
        "    return\n",
        "  for i in range(n * n):\n",
        "    img = mpimg.imread(img_directory + imgs[i])\n",
        "\t\t# define subplot\n",
        "    pyplot.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "    pyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "    pyplot.imshow(img)\n",
        "  pyplot.show()\n",
        "\n",
        "# load the face dataset\n",
        "print(f\"Directory contains {count_items(processed_dir)} items.\")\n",
        "plot_images(processed_dir, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPgC5SuUr5Br",
        "colab_type": "text"
      },
      "source": [
        "## Configure Training Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCxeMGGVlm08",
        "colab_type": "text"
      },
      "source": [
        "Define the training parameters.\n",
        "\n",
        "The `batch_size` parameter governs how many images are used for each update of the GAN. A larger size will train faster on a GPU, but too large a `batch_size` will cause a memory overflow error.\n",
        "\n",
        "The `feedback_factor` specifies how often to add to the logs and generate samples.\n",
        "\n",
        "The number of epochs specify how many iterations to run the GAN through before stopping training. This parameter is not that important because as long as you have the model files saved, you can resume training and train for more epochs. However, to get decent results, the number of epochs is usually greater than 150. This is highly dependent on your dataset also.\n",
        "\n",
        "If you are unsure what to choose, just use the defaults below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQAWdW6eXvdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "target_depth = int(math.log2(target_size) - 1)\n",
        "print(f\"Target depth = {target_depth}\")\n",
        "\n",
        "# how many images to process at once\n",
        "batch_size = 2**(11 - target_depth)\n",
        "print(f\"Batch size = {batch_size}\")\n",
        "\n",
        "# calculate feedback factor\n",
        "total_images = count_items(processed_dir)\n",
        "total_batches = total_images // batch_size\n",
        "feedback_factor = min(total_batches, 10)\n",
        "print(f\"Feedback factor = {feedback_factor}\")\n",
        "\n",
        "# number of iterations used for training\n",
        "# increase this number to train for longer\n",
        "num_epochs = 180"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziIscmhQeZq4",
        "colab_type": "text"
      },
      "source": [
        "Check if there are any previous models in the models_dir. If there are, assume training should be resumed instead of restarted.\n",
        "\n",
        "If you would like to start training over, make sure the models folder does not contain previous models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GBPqyVFdrxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if there are model files in the models_dir\n",
        "model_files = os.listdir(models_dir)\n",
        "epoch_reached = 0\n",
        "\n",
        "if len(model_files) > 0:\n",
        "  # we want to resume training\n",
        "  # first find what epoch we are up to\n",
        "  epoch_reached = getEpochReached(models_dir)\n",
        "  gen_file = os.path.join(models_dir, \"GAN_GEN_\" + str(epoch_reached) + \".pth\")\n",
        "  dis_file = os.path.join(models_dir, \"GAN_DIS_\" + str(epoch_reached) + \".pth\")\n",
        "  gen_shadow_file = os.path.join(\n",
        "      models_dir, \"GAN_GEN_SHADOW_\" + str(epoch_reached) + \".pth\"\n",
        "  )\n",
        "  gen_optim_file = os.path.join(\n",
        "      models_dir, \"GAN_GEN_OPTIM_\" + str(epoch_reached) + \".pth\"\n",
        "  )\n",
        "  dis_optim_file = os.path.join(\n",
        "      models_dir, \"GAN_DIS_OPTIM_\" + str(epoch_reached) + \".pth\"\n",
        "  )\n",
        "  print(f\"Found model files. Starting from epoch: {epoch_reached + 1}.\")\n",
        "else:\n",
        "  print(\"Model files not found. Starting from epoch 0.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCsuwg4Askmd",
        "colab_type": "text"
      },
      "source": [
        "## Train the GAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EspCKOCwlRZd",
        "colab_type": "text"
      },
      "source": [
        "To see all the options available for training the GAN, set `show_help` to `True` and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC6hVjBO_Elr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title  { run: \"auto\" }\n",
        "show_help = False #@param {type: \"boolean\"}\n",
        "if show_help:\n",
        "  !python train.py --help"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rRqMcdK6FAR",
        "colab_type": "text"
      },
      "source": [
        "### Start Training!\n",
        "The cell below runs the actual training on the GAN. It will run continuously until stopped or it times out. If you lose connection to this page, don't worry, you have about 40 minutes to reconnect without losing any progress. The notebook will continue to run on the Google Colab server for up to 40 minutes with no connection.\n",
        "\n",
        "Note that after about 12 hours, your Google Colab backend will be reset, so you can only train for 12 hours at most."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p0bBdeKeSFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/BMSG-GAN/sourcecode/\n",
        "# if the depth_reached is greater than 0,\n",
        "# then that means we are resuming a training session\n",
        "if epoch_reached > 0:\n",
        "  !python train.py \\\n",
        "               --depth=\"{target_depth}\" \\\n",
        "               --num_epochs=\"{num_epochs}\" \\\n",
        "               --flip_augment=True \\\n",
        "               --images_dir=\"{processed_dir}\" \\\n",
        "               --sample_dir=\"{samples_dir}\" \\\n",
        "               --model_dir=\"{models_dir}\" \\\n",
        "               --batch_size=\"{batch_size}\" \\\n",
        "               --feedback_factor=\"{feedback_factor}\" \\\n",
        "               --start=\"{epoch_reached + 1}\" \\\n",
        "               --generator_file=\"{gen_file}\" \\\n",
        "               --discriminator_file=\"{dis_file}\" \\\n",
        "               --shadow_generator_file=\"{gen_shadow_file}\" \\\n",
        "               --generator_optim_file=\"{gen_optim_file}\" \\\n",
        "               --discriminator_optim_file=\"{dis_optim_file}\"\n",
        "else:\n",
        "  !python train.py \\\n",
        "               --depth=\"{target_depth}\" \\\n",
        "               --num_epochs=\"{num_epochs}\" \\\n",
        "               --flip_augment=True \\\n",
        "               --images_dir=\"{processed_dir}\" \\\n",
        "               --sample_dir=\"{samples_dir}\" \\\n",
        "               --model_dir=\"{models_dir}\" \\\n",
        "               --batch_size=\"{batch_size}\" \\\n",
        "               --feedback_factor=\"{feedback_factor}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQqRydURYIB-",
        "colab_type": "text"
      },
      "source": [
        "## Cleanup Samples and Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAXpN4Ld-oZY",
        "colab_type": "text"
      },
      "source": [
        "### Cleanup Image Samples\n",
        "\n",
        "This is only necessary to run if you are storing samples in Google Drive. This deletes all generated image samples except for the last one from each epoch. Make sure to \"Empty Trash\" in Drive to recover the space.\n",
        "\n",
        "Keeping the last sample from each epoch is useful if you would like to make a gif of the progress of the GAN overtime (see last section)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nie6ARxzcdB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def cleanupSamples(total_depth, max_epochs):\n",
        "  for depth in range(2, total_depth + 2):\n",
        "    imsize = 2**depth\n",
        "    current_dir = os.path.join(samples_dir, f\"{imsize}_x_{imsize}\")\n",
        "    print(f\"Processing {imsize}_x_{imsize} images\")\n",
        "    deleteExtraImages(current_dir, max_epochs)\n",
        "    if len(os.listdir(current_dir)) > max_epochs:\n",
        "      print(f\"Something went wrong for {imsize}_x_{imsize} images\")\n",
        "      return\n",
        "  \n",
        "def deleteExtraImages(current_dir, max_epochs):\n",
        "  imgs_to_keep = [0]*(max_epochs + 1)\n",
        "  imgs = os.listdir(current_dir)\n",
        "  progress = ProgressBar(maxValue = len(imgs) - 1)\n",
        "  for i, f in enumerate(imgs):\n",
        "    # format of file name is \"gen_1_100.png\"\n",
        "    # where the first number is the epoch, and the second is the iteration\n",
        "    # we want to keep the file with the largest iteration per epoch\n",
        "    epoch_num, iter_num = re.findall(r'\\d+', f)\n",
        "    epoch_num = int(epoch_num)\n",
        "    iter_num = int(iter_num)\n",
        "    if epoch_num == None or iter_num == None or epoch_num > max_epochs:\n",
        "      # not enough numbers found so file is something else\n",
        "      continue\n",
        "    if iter_num > imgs_to_keep[epoch_num]:\n",
        "      # current file has a higher iteration number than the one in imgs_to_keep\n",
        "      # keep the current one and delete the one in imgs_to_keep\n",
        "      file_to_remove = f\"gen_{epoch_num}_{imgs_to_keep[epoch_num]}.png\"\n",
        "      imgs_to_keep[epoch_num] = iter_num\n",
        "    else:\n",
        "      # the current iter num is smaller than the one to keep, delete the file\n",
        "      file_to_remove = f\n",
        "    full_remove_path = os.path.join(current_dir, file_to_remove)\n",
        "    if os.path.exists(full_remove_path):\n",
        "      # check if the path exists before removing because imgs_to_keep\n",
        "      # is initialized to 0, which may not be a valid iteration number\n",
        "      os.remove(full_remove_path)\n",
        "    progress.update(i)\n",
        "\n",
        "if use_drive and samples_in_drive:\n",
        "  max_epoch = getEpochReached(models_dir)\n",
        "  # add 1 to max_epoch because the epoch that was interrupted\n",
        "  # should also be processed\n",
        "  cleanupSamples(target_depth, max_epoch + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWPva_dg_Pvh",
        "colab_type": "text"
      },
      "source": [
        "### Cleanup Models\n",
        "\n",
        "This is only necessary if you are using Google Drive (use_drive is True). It deletes all non-generator models but the ones saved from the last two epochs. If you would also like to delete old generator files, set `delete_generator` to `True`. It's important to do this to free up Drive storage. Make sure to 'Empty Trash' after running this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wTmw12rrZbI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "delete_generator = False  #@param {type: \"boolean\"}\n",
        "\n",
        "import os\n",
        "\n",
        "# Delete all models up to max_epochs except generator files\n",
        "def deleteModels(delete_dir, max_epochs):\n",
        "  progress = ProgressBar(maxValue = max_epochs)\n",
        "  for epoch_num in range(1, max_epochs + 1):\n",
        "    # format of file name is \"GAN_GEN_2.pth\"\n",
        "    # where the number is the epoch\n",
        "    files_to_remove = [f\"GAN_GEN_SHADOW_{epoch_num}.pth\",\n",
        "                       f\"GAN_GEN_OPTIM_{epoch_num}.pth\",\n",
        "                       f\"GAN_DIS_OPTIM_{epoch_num}.pth\",\n",
        "                       f\"GAN_DIS_{epoch_num}.pth\"]\n",
        "    if delete_generator:\n",
        "      files_to_remove.append(f\"GAN_GEN_{epoch_num}.pth\")\n",
        "    for file_to_remove in files_to_remove:\n",
        "      full_remove_path = os.path.join(delete_dir, file_to_remove)\n",
        "      if os.path.exists(full_remove_path):\n",
        "        # check if the path exists before removing\n",
        "        os.remove(full_remove_path)\n",
        "    progress.update(epoch_num)\n",
        "\n",
        "if use_drive:\n",
        "  max_epoch = getEpochReached(models_dir)\n",
        "  # keep models for last 2 epochs just in case\n",
        "  deleteModels(models_dir, max_epoch - 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB9i9aHw2QQG",
        "colab_type": "text"
      },
      "source": [
        "## Generate Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n278r0A3iou8",
        "colab_type": "text"
      },
      "source": [
        "### Generate a Single Image\n",
        "\n",
        "Generate an image from the most-trained generator and display it. If you would also like to save the generated image, set `save_image` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkddVo7A1Bwq",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Generate an Image { form-width: \"40%\" }\n",
        "\n",
        "#@markdown Set the checkbox below if you want to save the image.\n",
        "save_image = True  #@param {type: \"boolean\"}\n",
        "#@markdown If you aren't using Google Drive, the name of the generated directory\n",
        "#@markdown doesn't really matter\n",
        "generated_dir_name = \"generated\"  #@param {type: \"string\"}\n",
        "generated_dir = samples_dir + f\"/{generated_dir_name}/\"\n",
        "\n",
        "%cd /content/BMSG-GAN/sourcecode/\n",
        "\n",
        "from pathlib import Path\n",
        "import uuid\n",
        "import torch as th\n",
        "from torch.nn.functional import interpolate\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from MSG_GAN.GAN import Generator\n",
        "\n",
        "# The functions below are licensed with the MIT license.\n",
        "# They have been modified slightly.\n",
        "# Original author: Animesh Karnewar\n",
        "# Source: https://github.com/akanimax/BMSG-GAN\n",
        "\n",
        "def adjust_dynamic_range(data, drange_in=(-1, 1), drange_out=(0, 1)):\n",
        "    \"\"\"\n",
        "    adjust the dynamic colour range of the given input data\n",
        "    :param data: input image data\n",
        "    :param drange_in: original range of input\n",
        "    :param drange_out: required range of output\n",
        "    :return: img => colour range adjusted images\n",
        "    \"\"\"\n",
        "    if drange_in != drange_out:\n",
        "        scale = (np.float32(drange_out[1]) - np.float32(drange_out[0])) / (\n",
        "                np.float32(drange_in[1]) - np.float32(drange_in[0]))\n",
        "        bias = (np.float32(drange_out[0]) - np.float32(drange_in[0]) * scale)\n",
        "        data = data * scale + bias\n",
        "    return th.clamp(data, min=0, max=1)\n",
        "\n",
        "def progressive_upscaling(images):\n",
        "    \"\"\"\n",
        "    upsamples all images to the highest size ones\n",
        "    :param images: list of images with progressively growing resolutions\n",
        "    :return: images => images upscaled to same size\n",
        "    \"\"\"\n",
        "    with th.no_grad():\n",
        "        for factor in range(1, len(images)):\n",
        "            images[len(images) - 1 - factor] = interpolate(\n",
        "                images[len(images) - 1 - factor],\n",
        "                scale_factor=pow(2, factor)\n",
        "            )\n",
        "\n",
        "    return images\n",
        "\n",
        "# latent_size must be equal to size generator was trained with\n",
        "# depth must be equal to depth generator was trained with\n",
        "def generate_image(generator_file, depth, latent_size=512):\n",
        "# create the generator object\n",
        "    gen = th.nn.DataParallel(Generator(\n",
        "        depth=depth,\n",
        "        latent_size=latent_size\n",
        "    ))\n",
        "\n",
        "    print(\"Loading the generator weights from:\", generator_file)\n",
        "    # load the weights into it\n",
        "    device = th.device(\"cuda\" if th.cuda.is_available() \n",
        "                   else \"cpu\")\n",
        "    gen.load_state_dict(\n",
        "        th.load(generator_file, map_location=str(device))\n",
        "    )\n",
        "\n",
        "    print(\"Generating image...\")\n",
        "    # generate the images:\n",
        "    with th.no_grad():\n",
        "        point = th.randn(1, latent_size)\n",
        "        point = (point / point.norm()) * (latent_size ** 0.5)\n",
        "        ss_images = gen(point)\n",
        "\n",
        "    # resize the images:\n",
        "    ss_images = [adjust_dynamic_range(ss_image) for ss_image in ss_images]\n",
        "    ss_images = progressive_upscaling(ss_images)\n",
        "    ss_image = ss_images[depth - 1]\n",
        "\n",
        "    img = ss_image.squeeze(0).permute(1, 2, 0).cpu()\n",
        "    return img\n",
        "\n",
        "epoch_reached = getEpochReached(models_dir)\n",
        "gen_file = Path(models_dir) / (\"GAN_GEN_\" + str(epoch_reached) + \".pth\")\n",
        "img = generate_image(gen_file, target_depth)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "if save_image:\n",
        "    filename = uuid.uuid4().hex[:8]\n",
        "    Path(generated_dir).mkdir(parents=True, exist_ok=True)\n",
        "    plt.imsave(generated_dir + filename, img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nRgqg5biDA7",
        "colab_type": "text"
      },
      "source": [
        "### Download Generated Images\n",
        "\n",
        "Download the generated images if you wish. Set `num_files` to the maximum number of images you want to download. Note that `save_image` in the previous cell must be `True` in order to download images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXduuir_Q92H",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# max number of files to download\n",
        "#@markdown Max number if images to download\n",
        "num_files = 10  #@param {type: \"number\"}\n",
        "\n",
        "import tempfile\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "im_files = os.listdir(generated_dir)\n",
        "max_files = min(num_files, len(im_files))\n",
        "with tempfile.TemporaryDirectory() as tempdir:\n",
        "  zip_name = \"gen_images.zip\"\n",
        "  with zipfile.ZipFile(zip_name, \"w\", zipfile.ZIP_DEFLATED) as zip:\n",
        "    for i in range(max_files):\n",
        "      zip.write(generated_dir + im_files[i], im_files[i])\n",
        "  files.download(zip_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ4M7AA_i-N5",
        "colab_type": "text"
      },
      "source": [
        "### Generate GIF of training progress\n",
        "\n",
        "Set `download_image` to `True` to download the gif. Also choose which image in the samples grid to use by setting `image_y` and `image_x` which are 0-based indices starting in the top-left corner (i.e. the top-left image is 0, 0). Change `duration` to speed up or slow down the gif."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy1VHMIWvyKp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown Check the box below if you would like to download the \n",
        "#@markdown generated gif. If you are not using Google Drive you\n",
        "#@markdown should download the image because it is the only way to\n",
        "#@markdown view the gif.\n",
        "download_image = False  #@param {type: \"boolean\"}\n",
        "#@markdown Indices of the image in the samples grid to use. The\n",
        "#@markdown top-left corner is `image_y` = 0, `image_x` = 0.\n",
        "image_y = 0  #@param {type: \"number\"}\n",
        "image_x = 0  #@param {type: \"number\"}\n",
        "#@markdown Set the amount of time in milliseconds to display each\n",
        "#@markdown image in the gif\n",
        "duration = 250  #@param {type: \"number\"}\n",
        "gif_name = 'train_time_lapse.gif'  #@param {type: \"string\"}\n",
        "\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "from tqdm import tqdm\n",
        "\n",
        "def natural_key(string_):\n",
        "    \"\"\"See http://www.codinghorror.com/blog/archives/001018.html\"\"\"\n",
        "    string_ = str(string_)\n",
        "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]\n",
        "\n",
        "sample_image_dir = Path(samples_dir) / f\"{target_size}_x_{target_size}\"\n",
        "start_x = target_size * image_x\n",
        "end_x = start_x + target_size\n",
        "start_y = target_size * image_y\n",
        "end_y = start_y + target_size\n",
        "coords = (start_x, start_y, end_x, end_y)\n",
        "\n",
        "images = []\n",
        "for img in tqdm(sorted(sample_image_dir.iterdir(), key=natural_key)):\n",
        "  oimg = Image.open(img)\n",
        "  cimg = oimg.crop(coords)\n",
        "  images.append(cimg)\n",
        "images[0].save(samples_dir + gif_name,\n",
        "            save_all=True,\n",
        "            append_images=images[1:],\n",
        "            duration=duration,\n",
        "            loop=0)\n",
        "if download_image:\n",
        "  files.download(samples_dir + gif_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}